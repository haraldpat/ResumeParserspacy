{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Resume Parsing using AI(NLP)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m9lgAl2V1YhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resume parser is a powerful tool to parse the complete resume and see the necessary details you want to see. In this world where the employees are blooming, there are lots of people who apply in certain organisation but the hiring managers have certain limited amount of time, so resume parser can be the right step in order to simplify this process of getting the particular information from the resume."
      ],
      "metadata": {
        "id": "myWCtS5G1dg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can develop this resume parsing using two approaches:  \n",
        "(1) Traditional approach using regular expression and string matching  \n",
        "(2) using natural language processing to extract information  \n"
      ],
      "metadata": {
        "id": "gSmu5ZjQ1mG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I'll be using both of them for extracting different sections.Also, we'll be using one of the powerful libraries in nlp, i.e;spacy.<br>  \n",
        "SpaCy, a powerful open-source library for natural language processing (NLP) in Python, is a valuable tool in the context of resume parsing. It offers pre-trained models for tasks like named entity recognition (NER) and part-of-speech (POS) tagging, allowing it to effectively extract and categorize information from resumes."
      ],
      "metadata": {
        "id": "GsEGQwAL2Rey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!from spacy.lang.en import English\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1rGpQRwr0tb",
        "outputId": "ca568901-23ef-407d-f0e6-bd71d1f4e6d0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "/bin/bash: line 1: from: command not found\n",
            "2023-08-04 15:39:29.426460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to read our resume which is in pdf form, we will install **pdfminer** which just takes pdf as input and extracts all the text from it.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We need to also install **re** which is shorthand for regular expression.\n",
        "**Regular expression** can be used as a powerful tool to synthesize the text using some patterns(which could be written in regular expression).    \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Also we will use **matcher** which is from spacy library, it helps in matching sequences of tokens, based on pattern rules.\n",
        "The **Matcher** lets you find words and phrases using rules describing their token attributes. Rules can refer to token annotations (like the text or part-of-speech tags), as well as lexical attributes like Token.is_punct.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3Wdpy5z2pK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Va9ZRV-O-F",
        "outputId": "7480c6c9-713a-4e4d-a15a-6ae854c2e5bd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "import re\n",
        "import spacy\n",
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "V5ouJjyj-e3Q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will extract some basic information from the resume:\n",
        "\n",
        "1.   Skills\n",
        "2.   Name\n",
        "3.   Contact Number\n",
        "4.   E-mail\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp1yDoyc6q4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)"
      ],
      "metadata": {
        "id": "C-ZiQhzKDOue"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_paths = [r\"/content/Resume2.pdf\"]\n",
        "\n",
        "for resume_path in resume_paths:\n",
        "    text = extract_text_from_pdf(resume_path)\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy2w0nv4N6Fp",
        "outputId": "9c38abc8-6453-431e-9060-7ffa5be97ae7"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harsh Pathak \n",
            "\n",
            "Curious Entity \n",
            "\n",
            "A curious entity to learn and transform \n",
            "\n",
            "EDUCATION \n",
            "Undergraduate \n",
            "NIT Arunachal Pradesh \n",
            "12/2020 - P,  \n",
            "\n",
            "Fundamental topics of computer science \n",
            "\n",
            "Computer Science and\n",
            "engineering \n",
            "\n",
            "Higher Secondary(12th) \n",
            "Crystal International Public School \n",
            "05/2018 - 04/2020,  \n",
            "\n",
            "85% \n",
            "\n",
            "Fundamental knowledge in\n",
            "domain of Science(PCM) \n",
            "\n",
            "singhsima2000@gmail.com \n",
            "\n",
            "9898116490 \n",
            "\n",
            "linkedin.com/in/harsh-pathak-198259230 \n",
            "\n",
            "github.com/haraldpat \n",
            "\n",
            "SKILLS \n",
            "\n",
            "C/C++ \n",
            "\n",
            "Python \n",
            "\n",
            "JavaScript \n",
            "\n",
            "India \n",
            "\n",
            "Mathematics \n",
            "\n",
            "Problem Solving \n",
            "\n",
            "Data structure and Algorithm \n",
            "\n",
            "Java \n",
            "\n",
            "NodeJs \n",
            "\n",
            "ReactJs \n",
            "\n",
            "MongoDB \n",
            "\n",
            "MySQL \n",
            "\n",
            "Computer Architecture \n",
            "\n",
            "AI & ML \n",
            "\n",
            "India \n",
            "\n",
            "Computer Networking \n",
            "\n",
            "System Design \n",
            "\n",
            "DBMS \n",
            "\n",
            "Microsoft Oﬃce \n",
            "\n",
            "WORK EXPERIENCE \n",
            "INTERN \n",
            "Cotton University \n",
            "12/2022 - 05/2023,  \n",
            "INTERNSHIP ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS \n",
            "\n",
            "Achievements/Tasks \n",
            "\n",
            "Worked on real life data(DNA and RNA sequences) from NCBI and\n",
            "performed computations(machine learning algorithms) to understand the\n",
            "data and predict their behaviour. \n",
            "\n",
            "Contact :\n",
            "\n",
            "Dr. Manish Pratim Dutta \n",
            "\n",
            "-\n",
            "\n",
            "9800098563 \n",
            "\n",
            "PROJECTS \n",
            "Social Media Website (04/2023 - 06/2023) \n",
            "\n",
            "Full Stack website for friends build by MERN stack, also with a\n",
            "feature to chat. \n",
            "\n",
            "TechFest(Addovedi) Website (09/2022 - 10/2022) \n",
            "\n",
            "Front-End, UI-Design \n",
            "\n",
            "E-Commerce Website (Edulife India)\n",
            " (08/2022 - 09/2022) \n",
            "Full Stack Development \n",
            "\n",
            "EVENT COORDINATOR \n",
            "Addovedi Techfest \n",
            "10/2022 - 10/2022,  \n",
            "\n",
            "Computex Cup, Fu-Environment \n",
            "\n",
            "Management and Execution of events \n",
            "\n",
            "Created coding questions for computex cup \n",
            "\n",
            "INTERN \n",
            "Edulife India(AICTE approved) \n",
            "08/2022 - 10/2022,  \n",
            "IN-HOUSE INTERNSHIP ON WEB DEVELOPMENT \n",
            "\n",
            "Achievements/Tasks \n",
            "\n",
            "Created an E-Commerce website using M(MySql),E(Express,ejs) and\n",
            "Node.js . \n",
            "\n",
            "Contact :\n",
            "\n",
            "Sir Salam Charanjeet Singh \n",
            "\n",
            "-\n",
            "\n",
            "8794421389 \n",
            "\n",
            "ACHIEVEMENT \n",
            "Cleared GATE 2023 \n",
            "\n",
            "Competitive Programming \n",
            "Codechef(Ratings - 1539), Solved 200-250 problems of data structures and algorithm \n",
            "\n",
            "1st Prize in Quiz Competition NIT Arunachal Pradesh (08/2022) \n",
            "\n",
            "Won prizes in intermoral kabaddi league \n",
            "Allrounder \n",
            "\n",
            "SSB Recommended (11/2020) \n",
            "M-NDA (145) \n",
            "\n",
            "COURSES \n",
            "Statistics for Data Science \n",
            "\n",
            "India \n",
            "\n",
            "Introduction to Machine Learning\n",
            " (03/2023 - 04/2023) \n",
            "\n",
            "Web development (05/2022 - 07/2022) \n",
            "\n",
            "Python Programming (05/2022 - 07/2022) \n",
            "\n",
            "Digital Logic NPTEL (07/2021 - 10/2021) \n",
            "\n",
            "India \n",
            "\n",
            "LANGUAGES \n",
            "\n",
            "English \n",
            "Full Professional Proﬁciency \n",
            "\n",
            "Hindi \n",
            "Full Professional Proﬁciency \n",
            "\n",
            "Gujarati \n",
            "Professional Working Proﬁciency \n",
            "\n",
            "INTERESTS \n",
            "\n",
            "Hardware Design \n",
            "\n",
            "New Technologies \n",
            "\n",
            "AI and ML \n",
            "\n",
            "Cyber Security \n",
            "\n",
            "Competitive Programming \n",
            "\n",
            "Quantum Computing \n",
            "\n",
            "Kabaddi \n",
            "\n",
            "Table Tennis \n",
            "\n",
            "Investments \n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make a list of skills of which we want to be compulsory to be hired in organistaion and pass in this function, this function uses regular expression  to find the skills whether they are present or not, if they are present it will append to skills list.\n"
      ],
      "metadata": {
        "id": "RB6cLD_I6mDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills_from_resume(text, skills_list):\n",
        "    skills = []\n",
        "\n",
        "    for skill in skills_list:\n",
        "        pattern = r\"\\b{}\\b\".format(re.escape(skill))\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            skills.append(skill)\n",
        "\n",
        "    return skills"
      ],
      "metadata": {
        "id": "3ymriu4f_oQF"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_contact_number_from_resume(text):\n",
        "    contact_number = None\n",
        "\n",
        "    pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        contact_number = match.group()\n",
        "\n",
        "    return contact_number"
      ],
      "metadata": {
        "id": "BbyP5ZpgED8I"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_email_from_resume(text):\n",
        "    email = None\n",
        "\n",
        "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        email = match.group()\n",
        "\n",
        "    return email"
      ],
      "metadata": {
        "id": "_Sqqx3ISIkty"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to find name we will use spacy, we will use matcher for that and a pattern is defined as we know name consists of one/two/three proper noums in sequence, so we will use to find pattern where part of speech(POS) is a proper noun."
      ],
      "metadata": {
        "id": "kjMZaWKZKoE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_name(resume_text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "\n",
        "    patterns = [\n",
        "        [{'POS':'NOUN'},{'POS':'PROPN'}],\n",
        "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name and Last name\n",
        "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name, Middle name, and Last name\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        matcher.add('NAME', patterns=[pattern])\n",
        "\n",
        "    doc = nlp(resume_text) #this converts the text to tokens\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        return span.text\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "ZppHqiboIxAw"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    resume_paths = [r\"/content/Resume2.pdf\"]\n",
        "\n",
        "    for resume_path in resume_paths:\n",
        "        text = extract_text_from_pdf(resume_path)\n",
        "        print(\"Resume:\", resume_path)\n",
        "\n",
        "        name = extract_name(text)\n",
        "        if name:\n",
        "            print(\"Name:\", name)\n",
        "        else:\n",
        "            print(\"Name not found\")\n",
        "\n",
        "        contact_number = extract_contact_number_from_resume(text)\n",
        "        if contact_number:\n",
        "            print(\"Contact Number:\", contact_number)\n",
        "        else:\n",
        "            print(\"Contact Number not found\")\n",
        "\n",
        "        email = extract_email_from_resume(text)\n",
        "        if email:\n",
        "            print(\"Email:\", email)\n",
        "        else:\n",
        "            print(\"Email not found\")\n",
        "\n",
        "        skills_list = ['C/C++', 'Python', 'Machine Learning', 'Statistics', 'Math', 'JavaScript', 'mySql']\n",
        "        extracted_skills = extract_skills_from_resume(text, skills_list)\n",
        "        if extracted_skills:\n",
        "            print(\"Skills:\", extracted_skills)\n",
        "        else:\n",
        "            print(\"No skills found\")\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sAHLbOII2Zl",
        "outputId": "d79190f8-ebca-4724-91f5-95ee8e5cdaa7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume: /content/Resume2.pdf\n",
            "Name: Harsh Pathak\n",
            "Contact Number: 9898116490\n",
            "Email: singhsima2000@gmail.com\n",
            "Skills: ['Python', 'Machine Learning', 'Statistics', 'JavaScript', 'mySql']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have gathered the skills of an individual we want which is being matchef from what we want.  \n",
        "If the candidate has 50% of the skills required then he will be considered for further evaluation."
      ],
      "metadata": {
        "id": "aTdQYz2wOrE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(extracted_skills)>=(len(skills_list)/2):\n",
        "  print(f'{name}:ACCEPTED')\n",
        "else: print(f'{name}:NOT ACCEPTED')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QamN_shLJ2FR",
        "outputId": "2c5a8883-10b9-4750-b32b-1446df74fe0d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harsh Pathak:ACCEPTED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will feed many resumes to this program and check which of them are perfect candidate.\n"
      ],
      "metadata": {
        "id": "uMWZJpBWQjjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_list = [[r\"/content/Resume1.pdf\"],[r\"/content/Resume2.pdf\"],\n",
        "               [r\"/content/Resume3.pdf\"],[r\"/content/Resume4.pdf\"]]\n",
        "for resume in resume_list:\n",
        "  for resume_path in resume:\n",
        "        text = extract_text_from_pdf(resume_path)\n",
        "        name = extract_name(text)\n",
        "        extracted_skills = extract_skills_from_resume(text, skills_list)\n",
        "\n",
        "        #Name\n",
        "        print(name)\n",
        "\n",
        "        #Conatact Number\n",
        "        contact_number = extract_contact_number_from_resume(text)\n",
        "        if contact_number:\n",
        "            print(\"Contact Number:\", contact_number)\n",
        "        else:\n",
        "            print(\"Contact Number not found\")\n",
        "\n",
        "        #E-Mail\n",
        "        email = extract_email_from_resume(text)\n",
        "        if email:\n",
        "            print(\"Email:\", email)\n",
        "        else:\n",
        "            print(\"Email not found\")\n",
        "\n",
        "        #MATCHED SKILLS\n",
        "        if extracted_skills:\n",
        "            print(\"Skills:\", extracted_skills)\n",
        "        else:\n",
        "            print(\"No skills found\")\n",
        "\n",
        "        #FINAL STATUS\n",
        "        if len(extracted_skills)>=(len(skills_list)/2):\n",
        "            print(f'STATUS : ACCEPTED')\n",
        "        else: print(f'STATUS : NOT ACCEPTED')\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJT2bvUeP2dH",
        "outputId": "93a9f3f6-1ad5-44e7-db95-7ae54ad874f7"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BABURAM YADAV\n",
            "Contact Number: 917376356928\n",
            "Email: baburamyadav2690@gmail.com\n",
            "Skills: ['Python', 'Machine Learning', 'Statistics', 'JavaScript']\n",
            "STATUS : ACCEPTED\n",
            "\n",
            "Harsh Pathak\n",
            "Contact Number: 9898116490\n",
            "Email: singhsima2000@gmail.com\n",
            "Skills: ['Python', 'Machine Learning', 'Statistics', 'JavaScript', 'mySql']\n",
            "STATUS : ACCEPTED\n",
            "\n",
            "Patel Parag\n",
            "Contact Number: 8320134512\n",
            "Email: paragpagtel2908483@gmail.com\n",
            "No skills found\n",
            "STATUS : NOT ACCEPTED\n",
            "\n",
            "Sonu Paswan\n",
            "Contact Number not found\n",
            "Email: paswansonu578@gmail.com\n",
            "Skills: ['JavaScript', 'mySql']\n",
            "STATUS : NOT ACCEPTED\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMedzvqXQ0_A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}